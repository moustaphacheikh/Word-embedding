{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions d'aide\n",
    "\n",
    "cette section contient des méthodes dont nous avons besoin pour effectuer le prétraitement et le nettoyage des données.\n",
    "\n",
    "Si vous trouvez un problème lié à nltk, vous pouvez exécuter ce code et télécharger les fichiers nécessaires\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "nltk.download()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_whitespace(string):\n",
    "    string = re.sub(r'\\s+', ' ', string)\n",
    "    return re.sub(r\"\\s{2,}\", \" \", string).strip()\n",
    "\n",
    "def remove_punctiation(string):\n",
    "    return re.sub(\n",
    "        r'[\\u060C\\u061B\\u061F\\u0660\\u0661\\u0662\\u0663\\u0664\\u0665\\u0666\\u0667\\u0668\\u0669\\u066A\\u066B\\u066C\\u066D\\u0640]',\n",
    "        '', string)\n",
    "def remove_dubplicated_letters(string):\n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1',string)\n",
    "\n",
    "def remove_mentions(string):\n",
    "    regex = re.compile(r\"@[a-zA-Z0-9-_]+\")\n",
    "    return re.sub(regex, ' ', string)\n",
    "\n",
    "def remove_hashtags(string):\n",
    "    regex = re.compile(\"(?:^|\\s)[＃#]{1}(\\w+)\", re.UNICODE)\n",
    "    return re.sub(regex, ' ', string)\n",
    "\n",
    "def remove_emojis(string):\n",
    "    regex = re.compile(u'['\n",
    "                         u'\\U0001F300-\\U0001F64F'\n",
    "                         u'\\U0001F680-\\U0001F6FF'\n",
    "                         u'\\u2600-\\u26FF\\u2700-\\u27BF]+', re.UNICODE)\n",
    "    return re.sub(regex, ' ', string)\n",
    "\n",
    "\n",
    "def remove_stop_words(string, stop_words=[]):\n",
    "    words = []\n",
    "    tokens = word_tokenize(string)\n",
    "    for w in tokens:\n",
    "        if w not in stop_words:\n",
    "            words.append(w)\n",
    "    return \" \".join(words)\n",
    "def number_of_urls(string):\n",
    "    regex = re.compile(r\"(http|https|ftp)://[a-zA-Z0-9\\./]+\")\n",
    "    return len(re.findall(regex,string))\n",
    "\n",
    "def number_of_hashtags(string):\n",
    "    regex = re.compile(r'[#]')\n",
    "    return len(re.findall(regex, string))\n",
    "\n",
    "def number_of_mentions(string):\n",
    "    regex = re.compile(r\"@[a-zA-Z0-9-]+\")\n",
    "    return len(re.findall(regex, string))\n",
    "\n",
    "def number_of_emojis(string):\n",
    "    pattern = re.compile(u'['\n",
    "                         u'\\U0001F300-\\U0001F64F'\n",
    "                         u'\\U0001F680-\\U0001F6FF'\n",
    "                         u'\\u2600-\\u26FF\\u2700-\\u27BF]+', re.UNICODE)\n",
    "    iterator = re.findall(pattern, string)\n",
    "    emojis = []\n",
    "    for emoji in iterator:\n",
    "        for m in emoji:\n",
    "            emojis.append(m)\n",
    "    return len(emojis) \n",
    "\n",
    "def remove_urls(string):\n",
    "    regex = re.compile(r\"(http|https|ftp)://[a-zA-Z0-9\\./]+\")\n",
    "    return re.sub(regex, ' ', string)\n",
    "\n",
    "def filter_data(data,max_mentions,max_urls,max_emojis,max_hashtags,min_length):\n",
    "    data = data[(data.number_urls<= max_urls)&(data.number_mentions <= max_mentions)]\n",
    "    data = data[(data.number_emojis <= max_emojis)&(data.number_hashtags <= max_hashtags)]\n",
    "    return data[(data.length >= min_length)][['message']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lire les données et ajouter des métadonnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"stage.json\")\n",
    "data = data.rename(columns={0: 'message'})\n",
    "data[\"number_hashtags\"] = data[\"message\"].apply(number_of_hashtags)\n",
    "data[\"number_emojis\"] = data[\"message\"].apply(number_of_emojis)\n",
    "data[\"length\"] = data[\"message\"].apply(len)\n",
    "data[\"number_urls\"] = data[\"message\"].apply(number_of_urls)\n",
    "data[\"number_mentions\"] = data[\"message\"].apply(number_of_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>number_hashtags</th>\n",
       "      <th>number_emojis</th>\n",
       "      <th>length</th>\n",
       "      <th>number_urls</th>\n",
       "      <th>number_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bon go faire les cartons, 8semaines pour démén...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARK Coop #36 : NOUVELLE MAISON &amp;amp; HALLOWEEN...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  number_hashtags  \\\n",
       "0  Bon go faire les cartons, 8semaines pour démén...                0   \n",
       "1  ARK Coop #36 : NOUVELLE MAISON &amp; HALLOWEEN...                6   \n",
       "\n",
       "   number_emojis  length  number_urls  number_mentions  \n",
       "0              0      60            0                0  \n",
       "1              0     139            2                0  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrer les données\n",
    "\n",
    "Ces filtres vous pouvez utiliser sur les données brutes avant l'annotation. vous pouvez par exemple supprimer tous les tweets contenant plus de 2 hashtags ou plus d'un lien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mentions = 100\n",
    "max_urls = 100\n",
    "max_emojis = 100\n",
    "max_hashtags = 100\n",
    "min_length = 0\n",
    "data = filter_data(data,max_mentions,max_urls,max_emojis,max_hashtags,min_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bon go faire les cartons, 8semaines pour démén...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARK Coop #36 : NOUVELLE MAISON &amp;amp; HALLOWEEN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message\n",
       "0  Bon go faire les cartons, 8semaines pour démén...\n",
       "1  ARK Coop #36 : NOUVELLE MAISON &amp; HALLOWEEN..."
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyer les données\n",
    "\n",
    "Vous pouvez choisir les méthodes à appliquer dans le traitement juste commenter ce que vous n'avez pas besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(string):\n",
    "    # remove urls\n",
    "    string  = remove_urls(string) \n",
    "    # remove dubplicated letters\n",
    "    string = remove_dubplicated_letters(string)\n",
    "    # remove mentions \n",
    "    string = remove_mentions(string)\n",
    "    # remove hashtasgs\n",
    "    string = remove_hashtags(string)\n",
    "    # remove punctiations\n",
    "    #string = remove_punctiation(string)\n",
    "    string = \" \".join(word_tokenize(string, language='french'))\n",
    "    # remove extra white spaces\n",
    "    string = remove_extra_whitespace(string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"message\"] = data[\"message\"].apply(lambda string : string.replace('\\'','’'))\n",
    "data[\"nettoyer\"] = data[\"message\"].apply(preprocessing)\n",
    "reg = '[!\"%\\'()̣*+,-./:;<=>?\\[\\]^_`{|}~1234567890#’”“′‘\\\\\\]'\n",
    "data[\"nettoyer\"] = data[\"nettoyer\"].apply(lambda string : re.sub(reg,' ', string))\n",
    "regex = re.compile('[^a-zA-Z0-9àâéêèìôùûç _-’\\']')\n",
    "data[\"nettoyer\"] = data[\"nettoyer\"].apply(lambda string : regex.sub(' ', string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Après cette section, vous avez un message clair que vous pouvez utiliser pour chacune des étapes suivantes. l'atribut nettoyer a le message propre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>nettoyer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bon go faire les cartons, 8semaines pour démén...</td>\n",
       "      <td>Bon go faire les cartons semaines déménager pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARK Coop #36 : NOUVELLE MAISON &amp;amp; HALLOWEEN...</td>\n",
       "      <td>ARK Coop NOUVELLE MAISON amp HALLOWEEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voici l’état des lieux du parc de logements en...</td>\n",
       "      <td>Voici état lieux parc logements France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>En cette fin d’année j’ai géré une nouvelle vi...</td>\n",
       "      <td>En cette fin année géré nouvelle vie professio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>En plus je la commence dans une nouvelle maiso...</td>\n",
       "      <td>En plus commence nouvelle maison nouveau cheva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Donc j’me lève à 7h en vacance pour aller aide...</td>\n",
       "      <td>Donc lève h vacance aller aider mère peindre n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#demenagement à Latour bas-Elne près de #Perpi...</td>\n",
       "      <td>Latour bas Elne près</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ok, j’y vois un peu plus clair dans l’empaquet...</td>\n",
       "      <td>ok vois peu plus clair empaquetage donc carton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bon bah pas de salle aujourd’hui. Ça va porter...</td>\n",
       "      <td>Bon bah salle aujourd hui Ça va porter cartons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#JeVeuxUnQledTV car il me fait une tv pour not...</td>\n",
       "      <td>car fait tv nouvelle maison vacances</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  \\\n",
       "0  Bon go faire les cartons, 8semaines pour démén...   \n",
       "1  ARK Coop #36 : NOUVELLE MAISON &amp; HALLOWEEN...   \n",
       "2  Voici l’état des lieux du parc de logements en...   \n",
       "3  En cette fin d’année j’ai géré une nouvelle vi...   \n",
       "4  En plus je la commence dans une nouvelle maiso...   \n",
       "5  Donc j’me lève à 7h en vacance pour aller aide...   \n",
       "6  #demenagement à Latour bas-Elne près de #Perpi...   \n",
       "7  ok, j’y vois un peu plus clair dans l’empaquet...   \n",
       "8  Bon bah pas de salle aujourd’hui. Ça va porter...   \n",
       "9  #JeVeuxUnQledTV car il me fait une tv pour not...   \n",
       "\n",
       "                                            nettoyer  \n",
       "0  Bon go faire les cartons semaines déménager pl...  \n",
       "1             ARK Coop NOUVELLE MAISON amp HALLOWEEN  \n",
       "2             Voici état lieux parc logements France  \n",
       "3  En cette fin année géré nouvelle vie professio...  \n",
       "4  En plus commence nouvelle maison nouveau cheva...  \n",
       "5  Donc lève h vacance aller aider mère peindre n...  \n",
       "6                               Latour bas Elne près  \n",
       "7  ok vois peu plus clair empaquetage donc carton...  \n",
       "8  Bon bah salle aujourd hui Ça va porter cartons...  \n",
       "9               car fait tv nouvelle maison vacances  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_stopwords =  stopwords.words('French')\n",
    "# remove french stop words\n",
    "data[\"nettoyer\"] = data[\"nettoyer\"].apply(lambda string : remove_stop_words(string , french_stopwords))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
